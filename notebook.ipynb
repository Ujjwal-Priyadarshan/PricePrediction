{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f3a9ea",
   "metadata": {},
   "source": [
    "<h1> Price Prediction for Cars </h1>\n",
    "using given sample data\n",
    "\n",
    "* Step 1: testing if python setup for jupiter notebook is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9daa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989822e",
   "metadata": {},
   "source": [
    "* Step 2: install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b19afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.40.41-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 KB\u001b[0m \u001b[31m377.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting s3transfer<0.15.0,>=0.14.0\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 KB\u001b[0m \u001b[31m723.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/lib/python3/dist-packages (from boto3) (0.10.0)\n",
      "Collecting botocore<1.41.0,>=1.40.41\n",
      "  Downloading botocore-1.40.41-py3-none-any.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore<1.41.0,>=1.40.41->boto3) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /root/.local/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.41->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /root/.local/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.41->boto3) (1.17.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.23.34\n",
      "    Not uninstalling botocore at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "    Can't uninstall 'botocore'. No files were found to uninstall.\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.5.0\n",
      "    Not uninstalling s3transfer at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "    Can't uninstall 's3transfer'. No files were found to uninstall.\n",
      "Successfully installed boto3-1.40.41 botocore-1.40.41 s3transfer-0.14.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas\n",
      "  Downloading pandas-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m328.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 KB\u001b[0m \u001b[31m407.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 KB\u001b[0m \u001b[31m499.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.22.4\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m493.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /root/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.6 pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.8.0\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (2.2.6)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install boto3\n",
    "! pip install pandas\n",
    "! pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be08f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236483c5",
   "metadata": {},
   "source": [
    "* Step 3: visualize the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/sample_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09baa0",
   "metadata": {},
   "source": [
    "* Step 4: Remove Duplicate records\n",
    "\n",
    "in our sample there are no duplicate records. however keeping the cleanup step will help future datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many duplicates exist\n",
    "duplicates = df[df.duplicated(keep=False)]\n",
    "print(duplicates.to_string(index=False))\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eda468",
   "metadata": {},
   "source": [
    "* Step 5: eleminate records with NaN/Null values\n",
    "\n",
    "In general, if the NaN's are derivable, they should be derived. \n",
    "\n",
    "Note: But beaware that unknown value is not zero. that may express better results but that would corrupt the model to unrealisitic training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a653be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'carheight', 'curbweight', 'carlength', 'cylindernumber', 'enginesize', 'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg', 'Price']\n",
    "\n",
    "df = df.drop_duplicates(selected_columns, keep=False)\n",
    "df\n",
    "\n",
    "null_columns = df.columns[df.isnull().any()].tolist()\n",
    "null_columns\n",
    "\n",
    "columns_check = ['CarName', 'fueltype',\n",
    " 'carbody',\n",
    " 'enginelocation',\n",
    " 'carlength',\n",
    " 'cylindernumber',\n",
    " 'horsepower']\n",
    "\n",
    "rows_with_nulls = df[df[columns_check].isnull().any(axis=1)]\n",
    "rows_with_nulls\n",
    "\n",
    "df = df.dropna(subset=selected_columns)\n",
    "df\n",
    "\n",
    "rows_with_nulls = df[df[columns_check].isnull().any(axis=1)]\n",
    "rows_with_nulls[columns_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f7d55",
   "metadata": {},
   "source": [
    "* Step 6: ensure their are no corruption in data and if they are try to fix them or eleminate them from the sample.\n",
    "* Step 7: remove the columns that are unwanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a887523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "selected_columns = ['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'carheight', 'curbweight', 'cylindernumber', 'enginesize', 'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg', 'Price']\n",
    "# df['carsize'] = df['carheight'] * df['curbweight'] * df['enginesize']\n",
    "\n",
    "df = df.drop_duplicates(selected_columns)\n",
    "tiny_df = df[selected_columns]\n",
    "filtered_df = tiny_df[tiny_df[selected_columns].notna()]\n",
    "\n",
    "# filtered_df.head()\n",
    "sorted_df = filtered_df.sort_values(by='Price', ascending=True)\n",
    "#print(sorted_df);\n",
    "sorted_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6423a",
   "metadata": {},
   "source": [
    "<h2> Training the model </h2>\n",
    "* This is typical problem of prediction of a numerical value based on given parameter.\n",
    "* The model is basically a curve fitting problem where x are given properties and y is a point we are interested interested in.\n",
    "\n",
    "Regression Linear/Curve[non linear]\n",
    "\n",
    "NOTE: Our dataset is very small therefore Neural Networks wont be good approach. \n",
    "1.  define features, target, identify categorical feature and numeric features.\n",
    "2.  build the pipelines\n",
    "3.  split the dataset into Training and Testing dataset. \n",
    "4.  execute training process (fit)\n",
    "5.  execute the Test and evaluate the performance. (predict for the known targets)\n",
    "6.  execute the Predict on real world data to predict the Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632289bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "features = ['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'carheight', 'curbweight', 'cylindernumber', 'enginesize', 'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg']\n",
    "target = 'Price'\n",
    "\n",
    "x = df[features]\n",
    "y = df[target]\n",
    "\n",
    "categorical_features = ['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation']\n",
    "numeric_features = ['carheight', 'curbweight', 'cylindernumber', 'enginesize', 'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg']\n",
    "\n",
    "# Imputers for column transformation\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', categorical_imputer),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_features),\n",
    "    ('num', numeric_imputer, numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('regressor', LinearRegression())\n",
    "    ('RandomForest', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2dc48e",
   "metadata": {},
   "source": [
    "<h2> Training the model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de917768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and train\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dc8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, \"model.priceprediction.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3e272",
   "metadata": {},
   "source": [
    "<h2> Performance Evaluation </h2>\n",
    "The model is not performing very well. the Mean Squared Error is significantly high. \n",
    "Mean Squared Error: 7147802.95 is significanly high value.\n",
    "apparently the dataset is of large range too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b99c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Output results\n",
    "print(\"Predicted Prices:\", y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Error analysis\n",
    "y_test = np.array(y_test)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "diff  = y_test - y_pred\n",
    "print(f\" mean = {diff.mean()} \\n max= {diff.max()} \\n min = {diff.min()} \\n standard deviation = {diff.std()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
